[1mdiff --git a/kube-aws.md b/kube-aws.md[m
[1mindex c5d19c8..b5dd86c 100644[m
[1m--- a/kube-aws.md[m
[1m+++ b/kube-aws.md[m
[36m@@ -1,32 +1,29 @@[m
 #### Kubernetes en AWS[m
 [m
[31m- Hace un a√±o atr√°s deployar un cluster de Kubernetes desde cero no era tarea f√°cil, tenias que hacerlo a mano, crear tu propia herramienta o usar alguna soluci√≥n ya existente que no estaba ni completa ni muy bien documentada. Kubernetes era algo reservado solo a unos pocos conocedores del sistema o apasionados de las nuevas tecnolog√≠as. Si lo que quer√≠amos era un cluster en HA, resistente a fallos, con autoescalado, en tu hosting habitual y con el nivel de seguridad/fiabilidad de un entorno de producci√≥n la cosa ya se volv√≠a casi imposible. Mucha gente, entre los cuales me incluyo, desist√≠a al ver la faena que se le ven√≠a encima sin ver las ventajas que consigo tra√≠a. Un servidor miro varias veces la documentaci√≥n para hacerlo pero la complejidad de montarlo a mano, la indecisi√≥n de que herramienta usar y la falta de HA me hicieron desistir.[m
[32m+[m[32mHace un a√±o atr√°s deployar un cluster de Kubernetes desde cero no era tarea f√°cil, tenias que hacerlo a mano, crear tu propia herramienta o usar alguna soluci√≥n ya existente que no estaba ni completa ni muy bien documentada. Kubernetes era algo reservado solo a unos pocos expertos o apasionados de las nuevas tecnolog√≠as que se aventuraban a probar algo no del todo 'terminado'. Si lo que quer√≠as era un cluster en HA, resistente a fallos, con autoe scalado, en tu hosting habitual y con el nivel de seguridad/fiabilidad de un entorno de producci√≥n la cosa se volv√≠a imposible. Mucha gente, entre los cuales me incluyo, desist√≠a al ver la faena que se le ven√≠a encima sin ver las ventajas que consigo tra√≠a. No hab√≠a posibilidad de tener multi-zona en Amazon, a√∫n menos multi-master y otras tantas cosas que hac√≠an que uno no se animara a probar.[m
 [m
 <!-- TEASER_END -->[m
 [m
[31m-[m
[31m-Afortunadamente hoy en dia existen varias herramientas que nos facilitan esta tar√©a y se puede decir que algunas de ellas han madurado lo suficiente como para que los creadores de kubernetes decidan substituir su proipia herramienta "kubeup.sh" en favor de estas. Entre las mas conocidas y las √∫nicas recomendadas por Kubernetes estan Kops y kube-aws. Kops es capaz de desplegar un cluster de kubernetes en AWS haciendo uso de Terraform (infrastructura en c√≥digo de Hashicorp). kube-aws es una herramienta creada por CoreOS que hace uso de Cloudformation (infraestructura en c√≥digo de Amazon) y tambi√©n deploya en AWS.[m
[32m+[m[32mAfortunadamente las cosas han cambiado y hoy en d√≠a existen varias herramientas que nos facilitan esta tarea, se puede decir que algunas de ellas han madurado lo suficiente como para que los creadores de Kubernetes decidan substituir su propia herramienta "kubeup.sh" en favor de estas. Entre las mas conocidas y las √∫nicas recomendadas por Kubernetes est√°n Kops y kube-aws. Kops es capaz de desplegar un cluster de Kubernetes en AWS haciendo uso de Terraform(infrastructure as code de Hashicorp) y kube-aws hace lo mismo pero usando Cloudformation(infrastructure as code de Amazon). Todo y que antes no lo hac√≠an ahora estas soluciones ya disponen de la posibilidad de desplegar en multi-zona, multi-master, alta disponibilidad y muchas cosas mas.[m
 [m
 [m
 ###### kube-aws o pescando atunes en el para√≠so [m
 [m
[31m-Como  un servidor ya tenia Cloudformation por la mano y la infrastructura de mi empresa estaba en AWS lo m√°s l√≥gico era elegir kube-aws, no desplegar√≠a un cluster en otro hosting ni sab√≠a nada de Terraform. kube-aws me permit√≠a lanzar el cluster desde la propia herramienta o exportar el fichero a cloudformation el cual podia modificar a posteriori a mi gusto, esa fu√© realmente la clave de elegir kube-aws. A los quince minutos de haberme puesto a trastear con la herramienta tenia montado un cluster con 2 masters, 6 nodos, etcd y sobre mi VPC de Staging, que m√°s se pod√≠a pedir![m
[31m-[m
[31m-Una vez realizadas las comprobaciones de que con el cliente podia acceder al cluster me puse a mirar como desplegar una aplicaci√≥n sencilla, un cl√°sico, wordpress con mysql.[m
[32m+[m[32mPasado un tiempo de mi primer intento de entrar en el mundo de Kubernetes volv√≠ a revisar estas 2 herramientas y viendo que ya hab√≠an madurado bastante me decid√≠ a darle una oportunidad a kube-aws. Un servidor ya tenia Cloudformation por la mano y la infraestructura de mi empresa estaba en AWS con lo que lo m√°s l√≥gico era usar esta soluci√≥n. En aquel momento kube-aws ya permit√≠a desplegar nodos en multi-zona, a√∫n le faltaba multi-master y muchas cosas pero la velocidad a la que se le a√±ad√≠an features y el roadmap de futuras versiones me hicieron ver que si bien algunas de mis necesidades no estaban cubiertas en ese momento lo estar√≠an en poco tiempo. Tambi√©n contaba con la ventaja de que al basarse en Cloudformation, una vez realizado el template pod√≠a modificar el fichero para ajustar, a√±adir o quitar lo que me interesara.[m
 [m
[31m-Aqu√≠ la cosa ya cost√≥ un poco, la documentaci√≥n de Kubernetes no es que sea muy clara en algunos aspectos, lo b√°sico esta cubierto, lo complejo a veces no explicado con detalle o incompleto y las √∫ltimas features a√±adidas a veces ni aparecen, hay que ir buscando por Github y los foros donde, sin muchas complicaciones, se acaba encuentrando lo que se necesita.[m
[32m+[m[32mLa sorpresa fue grata ya que a los 15 minutos de trastear con kube-aws dispon√≠a de un cluster de Kubernetes en Amazon con un m√°ster, 6 nodos repartidos entre 2 zonas y todo listo para empezar a ver que se coc√≠a en ese mundillo que tanto revuelo hab√≠a suscitado.[m
 [m
[31m-Despu√©s de pelearme un poco con los ficheros de configuraci√≥n en YAML y queriendo deployar usando las ultimas features que habia implementado Kubernetes consegu√≠ lanzar un Wordpress conectado a un MySql y dicho blog publicado a trav√©s de un ELB de Amazon, solo me faltaba apuntar un DNS![m
[32m+[m[32mUna vez realizadas las comprobaciones conexi√≥n al cluster desde el cliente de Kubernetes me puse a mirar como desplegar una aplicaci√≥n sencilla, un cl√°sico, Wordpress con Mysql. Aqu√≠ la cosa ya cost√≥ un poco, la documentaci√≥n de Kubernetes no era muy clara en algunos aspectos, lo b√°sico estaba cubierto, lo complejo a veces no explicado con detalle o incompleto y las √∫ltimas features a√±adidas ni aparec√≠an. A veces hay que ir buscando por Github y los foros, donde sin muchas complicaciones se acaba encontrando lo que se necesita. Despu√©s de pelearme un poco con los ficheros de configuraci√≥n en YAML y queriendo deployar usando las √∫ltimas features que hab√≠a implementado Kubernetes consegu√≠ lanzar un Wordpress conectado a un MySql y dicho servicio publicado a trav√©s de un ELB de Amazon, ya solo me faltaba apuntar un DNS![m
 [m
 [m
[31m-###### La pot√©ncia de Kubernetes[m
[32m+[m[32m###### La potencia de Kubernetes[m
 [m
[31m-Sinceramente el despliegue que realiz√© es bastante sencillo una vez entendida la filosof√≠a de Kubernetes y su funcionamiento, pero hay tantas cosas que estan tan bien pensadas que vale la pena dedicarle tiempo a entender que es, como fuciona, que partes lo componen y las ventajas que trae consigo. Entre algunas de ellas y para no extenderme dir√© que tiene de salida y dejandome muchas en el tintero estas features:[m
[32m+[m[32mSinceramente lo que desplegu√© en ese momento y que me pareci√≥ una genialidad hoy en d√≠a me parece de primaria. Hay tantas cosas que est√°n tan bien pensadas en Kubernetes y que facilitan tanto las cosas que vale la pena dedicarle tiempo a entender que es, como funciona, que partes lo componen y las ventajas que consigo trae. Entre algunas de ellas y para no extenderme dir√© que tiene de salida, dej√°ndome muchas en el tintero, estas features:[m
 [m
 - Autodiscovery[m
 - Montaje de volumenes (Amazon EBS/EFS, GCE volumes)[m
 - Ficheros de configuraci√≥n actualizables en caliente[m
[31m-- Rolling updates y rollbacks automaticos[m
[32m+[m[32m- Rolling updates y rollbacks[m
 - Healthchecks[m
 - Autoscaling[m
 - Gesti√≥n de secrets[m
[36m@@ -39,35 +36,35 @@[m [mSinceramente el despliegue que realiz√© es bastante sencillo una vez entendida l[m
 y mucho m√°s[m
 [m
 [m
[31m-###### Entrando en detalle [m
[32m+[m[32m#### Entrando en detalle[m[41m [m
 [m
[31m-A partir de aqu√≠ voy a explicar paso a paso con detalle todo el proceso de instalaci√≥n, para los que sean vagos ya aviso que el art√≠culo va a ser bastante extenso, ahora bien, una vez finalizado tendremos a nuestra disposici√≥n un cluster de Kubernetes en HA preparado para deployar servicios en un entorno de pruebas/staging usando ELBs de Amazon y alguna cosa mas, en el tintero se quedaran el autoscaling de los nodos, auto-recuperaci√≥n del ETCD, registro automatico de DNS para los servicios y muchas cosas mas que ya cubriremos en futuros posts o que se pueden obtener con una peque√±a b√∫squeda por internet.[m
[32m+[m[32mAhora nos pondremos serios, a partir de aqu√≠ voy a explicar paso a paso con detalle todo el proceso de instalaci√≥n, para los que sean vagos ya aviso que el art√≠culo va a ser bastante extenso ahora bien, una vez finalizado tendremos a nuestra disposici√≥n un cluster de Kubernetes en HA preparado para deployar servicios en un entorno de pruebas/staging usando Amazon. En el tintero se quedaran el autoscaling de los nodos, auto-recuperaci√≥n del ETCD, registro autom√°tico de DNS para los servicios y muchas cosas mas que ya cubriremos en futuros posts o que se pueden aprender con una peque√±a b√∫squeda por Internet y paciencia.[m
 [m
 [m
 ###### Preparando el barco para zarpar[m
 [m
[31m-Doy por supuesto una s√©rie de conocimientos en Amazon que no cubrir√© aqu√≠ ya que no es el prop√≥sito de este blog ni de este art√≠culo, algunos de ellos se pueden aprender en poco tiempo y otros son mas costosos, que nadie desista en intentarlo ya que no todos son necesarios si lo √∫nico que queremos hacer es deplegar algo par empezar a jugar con Kubernetes.[m
[32m+[m[32mDoy por supuesto una serie de conocimientos en Amazon que no cubrir√© aqu√≠ ya que no es el prop√≥sito de este blog ni de este art√≠culo, algunos de ellos se pueden aprender en poco tiempo y otros son mas costosos, que nadie desista en intentarlo ya que no todos son necesarios si lo √∫nico que queremos hacer es desplegar algo par empezar a jugar con Kubernetes.[m
 [m
[31m-Tambi√©n ser√° necesario disponer del cliente de aws configurado con una access key id y secret access key con los permisos necesarios para que la herramienta pueda realizar cambios en AWS, si no es as√≠ el primer paso es crear un usario nuevo y configurar el cliente de AWS de linea de comandos, toda la informaci√≥n necesaria se puede encontrar en la web de amazon. Tambi√©n necesitaremos una clave KMS que podemos crear desde la consola de IAM de AWS as√≠ como una clave SSH para poder acceder a los nodos y un bucket de S3 para subir ficheros.[m
[32m+[m[32mTambi√©n ser√° necesario disponer del cliente de AWS configurado con una access key id y secret access key con los permisos necesarios para que la herramienta pueda realizar cambios en AWS, si no es as√≠ el primer paso es crear un usuario nuevo y configurar el cliente de AWS de linea de comandos, toda la informaci√≥n necesaria se puede encontrar en la web de Amazon. Tambi√©n necesitaremos una clave KMS que podemos crear desde la consola de IAM de AWS as√≠ como una clave SSH para poder acceder a los nodos y un bucket de S3 para subir ficheros.[m
 [m
[31m-Lo primero que tenemos que hacer para poder empezar a definir como ser√° nuestro cluster es bajarnos la herramienta kube-aws de github, la podemos encontrar en https://github.com/coreos/kube-aws. La podemos poner en una carpeta de nuestra elecci√≥n o copiarla en /usr/bin para mayor facilidad, la marcamos como ejecutable con el cl√°sico chmod +x y ya estamos listos para empezar.[m
[32m+[m[32mLo primero que tenemos que hacer para poder empezar a definir como ser√° nuestro cluster es bajarnos la herramienta kube-aws de Github que se puede  encontrar en https://github.com/coreos/kube-aws. La podemos poner en una carpeta de nuestra elecci√≥n o copiarla en /usr/bin para mayor facilidad, la marcamos como ejecutable con el cl√°sico chmod +x y ya estamos listos para empezar.[m
 [m
 [m
 ###### Inicializaci√≥n del template y personalizaci√≥n[m
 [m
 El primer paso para empezar a definir nuestro cluster en HA es inicializar un fichero de template que se usara para generar el fichero de configuraci√≥n final, para ello creamos un directorio vac√≠o y ejecutamos el siguiente comando:[m
[31m-[m
[32m+[m[32m```[m
 kube-aws init[m
[31m-[m
[31m-Al ejecutarlo si no ponemos ning√∫n par√°metro nos dar√° un error y nos dir√° que hay algunos par√°metros necesarios para su correcto funcionamiento que seran mas o menos estos:[m
[31m-[m
[32m+[m[32m```[m
[32m+[m[32mAl ejecutarlo si no ponemos ning√∫n par√°metro nos dar√° un error y nos dir√° que hay algunos par√°metros necesarios para su correcto funcionamiento que ser√°n mas o menos estos:[m
[32m+[m[32m```[m
 "--cluster-name", "--external-dns-name", "--region", "--availability-zone"[m
[31m-[m
[31m-El nombre del cluster, el nombre externo dns (importante que resuleva pq es el que usaran los nodos para la conexi√≥n con el master), la regi√≥n de Amazon y la zona de disponibilidad deseada. Hago hincapi√© en que en el external dns name deber√≠amos poner un nombre de un dominio existente y si puede ser que este en Route53, de esta manera podemos decirle a la herramienta que nos cree automaticamente el registro en Route53 y no tendremos que crearlo nosotros a posteriori.[m
[32m+[m[32m```[m
[32m+[m[32mEl nombre del cluster, el nombre externo DNS (importante que resuelva ya que es el que usaran los nodos para la conexi√≥n con el m√°ster), la regi√≥n de Amazon y la zona de disponibilidad deseada. Hago hincapi√© en que en el external DNS name deber√≠amos poner un nombre de un dominio existente y si puede ser que este en Route53, de esta manera podemos decirle a la herramienta que nos cree autom√°ticamente el registro en Route53 y no tendremos que crearlo nosotros a posteriormente.[m
 [m
 ¬øPorqu√© la zona de disponibilidad si queremos montar un cluster en HA? os preguntareis.... pues eso tambi√©n me pregunto yo, se que en las primeras versiones de esta herramienta no era posible montar un cluster en HA y creo que se han dejado este par√°metro como obligatorio cuando no deber√≠a serlo como veremos mas adelante.[m
 [m
[31m-Si ponemos los parametros que nos faltan obtendremos esto:[m
[32m+[m[32mSi ponemos los par√°metros que nos faltan obtendremos esto:[m
 ```[m
 kube-aws init --cluster-name k8s-kubeops --external-dns-name k8s.kubeops.net --region us-east-1 --availability-zone us-east-1a[m
 Success! Created cluster.yaml[m
[36m@@ -77,9 +74,9 @@[m [mNext steps:[m
 2. Use the "kube-aws render" command to render the CloudFormation stack template and coreos-cloudinit userdata.[m
 ```[m
 [m
[31m-Esto nos crear√° un fichero tipo template que ahora modificaremos par adaptar a nuestras necesidades, se puede ya lanzar tal y como esta pero siempre es bueno pegarle un vistazo para ajustar tipo de maquinas que compondran el cluster y algun parametro sobre las subnets para tener alta disponibilidad.[m
[32m+[m[32mEsto nos crear√° un fichero tipo template que ahora modificaremos par adaptar a nuestras necesidades, se puede ya lanzar tal y como esta pero siempre es bueno pegarle un vistazo para ajustar tipo de maquinas que compondr√°n el cluster y alg√∫n par√°metro sobre las subnets para tener alta disponibilidad.[m
 [m
[31m-Como el tama√±o del archivo es importante, voy a quitar todos los comentarios y opciones que no tocaremos en este art√≠culo, de todos modos es interesante leer el fichero original ya que hay muchisimas opciones que igual no tocamos hoy pero son de gran interes para un deploy en producci√≥n. Voy comentando dentro del fichero para simplificar el seguimiento de los par√°metros.[m
[32m+[m[32mComo el tama√±o del archivo es importante, voy a quitar todos los comentarios y opciones que no tocaremos en este art√≠culo, de todos modos es interesante leer el fichero original ya que hay much√≠simas opciones que igual no tocamos hoy pero son de gran inter√©s para un deploy en producci√≥n. Voy comentando dentro del fichero para simplificar el seguimiento de los par√°metros.[m
 [m
 [m
 ```[m
[36m@@ -102,10 +99,10 @@[m [mhostedZoneId: "AIX95O34ZN4A"[m
 # Descomentamos y ponemos el nombre de una llave SSH existente en AWS.[m
 keyName: 'kubeops-admin'[m
 [m
[31m-# La zona que hemos pasado por par√†metro[m
[32m+[m[32m# La zona que hemos pasado por par√°metro[m
 region: us-east-1[m
 [m
[31m-# La AZ que hemos pasado por par√†metro, la comentamos para obtener HA.[m
[32m+[m[32m# La AZ que hemos pasado por par√°metro, la comentamos para obtener HA.[m
 #availabilityZone: us-east-1a[m
 [m
 # El ARN de la key KMS de AWS, es una clave que podemos generar en el panel de IAM de AWS y nos servir√° [m
[36m@@ -114,10 +111,10 @@[m [mregion: us-east-1[m
 kmsKeyArn: ""[m
 [m
 # Descomentamos este, el n√∫mero de masters que queremos, como vamos a deployar solo en 2 [m
[31m-# zonas, lo pondremos a 2 aunqu√© podr√≠amos poner tranquilamente 4[m
[32m+[m[32m# zonas, lo pondremos a 2 pero podr√≠amos poner tranquilamente 4[m
 controllerCount: 2[m
 [m
[31m-# Descomentamos este, es el tipo de instancia que vamos a usar para los masters, no pongais nada mas peque√±o[m
[32m+[m[32m# Descomentamos este, es el tipo de instancia que vamos a usar para los masters, no pong√°is nada mas peque√±o[m
 # que el default o no arrancara el cluster, para nuestro prop√≥sito pondremos m3.medium.[m
 controllerInstanceType: m3.medium[m
 [m
[36m@@ -129,18 +126,18 @@[m [mworker:[m
     count: 4[m
 [m
 # Descomentamos este, el tipo de instancia de los workers, seg√∫n lo que queramos deployar ha de ser mayor o [m
[31m-# menor, para nuestro proposito pondremos las mismas que en los masters pero seg√∫n lo que queramos han de ser[m
[32m+[m[32m# menor, para nuestro prop√≥sito pondremos las mismas que en los masters pero seg√∫n lo que queramos han de ser[m
 # de mayor o menor tama√±o (para cosas mas serias mirar los pools de maquinas donde podremos especificar [m
 # varios tipos).[m
 workerInstanceType: m3.medium[m
 [m
[31m-# Descomentamos este si quieremos que los workers tengan un tama√±o de disco espec√≠fico, no es aconsejable [m
[32m+[m[32m# Descomentamos este si queremos que los workers tengan un tama√±o de disco espec√≠fico, no es aconsejable[m[41m [m
 # guardar datos en los discos de los nodos, mejor los subimos a 50G pero no los usaremos.[m
 workerRootVolumeSize: 50[m
 [m
 # Descomentamos este, par√°metro importante, el n√∫mero de nodos en el cluster etcd, aqu√≠ subiremos de 1 a 3 [m
[31m-# para tener alta disponibilidad, hay que tener en cuenta que kubernetes depende completamente de este [m
[31m-# cluster y a ser posible deber√≠a montarse por separado y tener algun sistema de auto-recovery.[m
[32m+[m[32m# para tener alta disponibilidad, hay que tener en cuenta que Kubernetes depende completamente de este[m[41m [m
[32m+[m[32m# cluster y a ser posible deber√≠a montarse por separado y tener alg√∫n sistema de auto-recovery.[m
 # Update: en las √∫ltimas versiones beta ya esta montado por separado y lleva ASG y auto-recovery.[m
 etcdCount: 3[m
 [m
[36m@@ -153,7 +150,7 @@[m [metcdInstanceType: m3.medium[m
 vpcCIDR: "10.0.0.0/16"[m
 [m
 # Descomentamos estos, aqu√≠ se pueden describir cuantas subnets queremos y de que tipo, p√∫blicas o privadas,[m
[31m-# para esta demo usaremos dos p√∫blicas per√≤ las best practices de AWS no aconsejan este tipo de deployment.[m
[32m+[m[32m# para esta demo usaremos dos p√∫blicas pero las best practices de AWS no aconsejan este tipo de deployment.[m
 subnets:[m
   - name: ManagedPublicSubnet1[m
     private: false[m
[36m@@ -171,19 +168,19 @@[m [mtlsCertDurationDays: 3650[m
 # Descomentamos este si queremos cambiar la versi√≥n del SO base.[m
 kubernetesVersion: v1.5.3_coreos.0[m
 [m
[31m-# Descomentamos estos para poner tags al cluster y asi podelos diferenciar cuanto tengamos varios clusters, [m
[32m+[m[32m# Descomentamos estos para poner tags al cluster y asi poderlos diferenciar cuanto tengamos varios clusters,[m[41m [m
 # realmente no es necesario si deployamos uno pero as√≠ vemos como queda todo[m
 stackTags:[m
   Name: "Kubernetes"[m
   Environment: "Kubeops"[m
 ```[m
 [m
[31m-Estos son los par√°metros b√°sicos que creo importantes para una primera toma de contacto de Kubernetes en AWS, hay bastantes mas que cubriremos en pr√≤ximos art√≠culos, esta herramienta dispone de demasiadas opciones como para aprenderlas todas de golpe y adem√°s explicar algo de Kubernetes en un solo post, sinceramente creo que ser√° demasiado largo y mas del 80% de la gente optar√° por parar ahora mismo, no lo hagais, vale la pena :)[m
[32m+[m[32mEstos son los par√°metros b√°sicos que creo importantes para una primera toma de contacto de Kubernetes en AWS, hay bastantes mas que cubriremos en pr√≥ximos art√≠culos, esta herramienta dispone de demasiadas opciones como para aprenderlas todas de golpe y adem√°s explicar algo de Kubernetes en un solo post, sinceramente creo que ser√° demasiado largo y mas del 80% de la gente optar√° por parar ahora mismo, no lo hag√°is, vale la pena :)[m
 [m
[31m-Dicho esto repasemos rapidamente lo que tenemos, vamos a crear un cluster con m√°quinas m3.medium para todos los nodos (masters, etcd y workers), con DNS, que seran deployados en 2 subnets p√∫blicas en un VPC nuevo y creando un registro DNS en un dominio que ya tenemos apuntado a Route53, ojo con el dominio y la key KMS. Sin estos recursos el cluster no va a funcionar y os frustrareis antes de tiempo ;-)[m
[32m+[m[32mDicho esto repasemos r√°pidamente lo que tenemos, vamos a crear un cluster con m√°quinas m3.medium para todos los nodos (masters, etcd y workers), con DNS, que ser√°n deployados en 2 subnets p√∫blicas en un VPC nuevo y creando un registro DNS en un dominio que ya tenemos apuntado a Route53, ojo con el dominio y la key KMS. Sin estos recursos el cluster no va a funcionar y os frustrareis antes de tiempo ;-)[m
 [m
 ###### Arrancando motores[m
[31m-Una vez tenemos el template modificado a nuestro gusto pasamos a la generaci√≥n de lo que realmente ser√° el fichero de configuraci√≥n que kube-aws usar√° para lanzar el cluster en Amazon, dicho archivo no es un Cloudformation pero deduzco que por detras crear√° uno que si que lo es a partir de este y lo lanzar√°, lo deduzco porqu√© podemos optar por exportar todo a un Cloudformation en vez de lanzar el cluster desde la herramienta y sospecho que es lo que hace el programa por detr√°s.[m
[32m+[m[32mUna vez tenemos el template modificado a nuestro gusto pasamos a la generaci√≥n de lo que realmente ser√° el fichero de configuraci√≥n que kube-aws usar√° para lanzar el cluster en Amazon, dicho archivo no es un Cloudformation pero deduzco que por detr√°s crear√° uno que si que lo es a partir de este y lo lanzar√°, lo deduzco porqu√© podemos optar por exportar todo a un Cloudformation en vez de lanzar el cluster desde la herramienta y sospecho que es lo que hace el programa por detr√°s.[m
 [m
 Para generar el "template" final y varios archivos extras que necesita la aplicaci√≥n ejecutaremos el siguiente comando aunque nos dice que ser√° deprecado en breve:[m
 [m
[36m@@ -222,25 +219,70 @@[m [mEsto nos va a generar una estructura de directorios como esta:[m
 [m
 Veremos que se han creado 4 directorios nuevos:[m
 [m
[31m-* Credentials: contiene las keys que se usaran para la comunicacion segura entre todas las partes del cluster.[m
[32m+[m[32m* Credentials: contiene las keys que se usaran para la comunicaci√≥n segura entre todas las partes del cluster.[m
 * kubeconfig: contiene la configuraci√≥n para el cliente de Kubernetes.[m
 * userdata: contiene todos los userdata para los masters, workers,etc.[m
[31m-* stack-templates: contiene todos los templates para generar los cloudformations necesarios.```[m
[31m-kube-aws up --s3-uri s3://kube-aws-edyo[m
[32m+[m[32m* stack-templates: contiene todos los templates para generar los Cloudformations necesarios.```[m
 [m
[31m-Con esto ya tenemos todos los pasos para deployar un cluster de kubernetes en versi√≥n development o test en AWS.[m
[32m+[m[32mCon esto ya tenemos todos los pasos para deployar un cluster de Kubernetes en versi√≥n development o test en AWS.[m
 [m
[31m-Para poder arrancar el cluster necesitamos un bucket de S3 donde se van a subir todas las definiciones de Cloudformation necesarias, en estas √∫ltimas versiones kube-aws crea un stack que lleva dentro 2 o m√°s stacks, uno para lo que le llaman el 'Control Plane' compuesto por los masters y los ETCDs y otro que sera el nodepool que hemos creado, si tuvieramos mas nodepools se crear√≠a un stack por cada uno de ellos para facilitar su posterior modificaci√≥n sin afectar al resto del cluster.[m
[32m+[m[32mPara poder arrancar el cluster necesitamos un bucket de S3 donde se van a subir todas las definiciones de Cloudformation necesarias, en estas √∫ltimas versiones kube-aws crea un stack que lleva dentro 2 o m√°s stacks, uno para lo que le llaman el 'Control Plane' compuesto por los masters y los ETCDs y otro que sera el nodepool que hemos creado, si tuvi√©ramos mas nodepools se crear√≠a un stack por cada uno de ellos para facilitar su posterior modificaci√≥n sin afectar al resto del cluster.[m
 [m
 Dicho esto ya solo nos queda lanzar el comando de creaci√≥n del stack apuntando a un bucket de S3 ya existente:[m
 ```[m
 kube-aws up --s3-uri s3://kube-aws-kubeops[m
 ```[m
[31m-A partir de aqu√≠ podremos seguir la creaci√≥n de todos estos stacks desde el dashboard de AWS Cloudformation, para los que no esteis familiarizados con esta herramienta solo hay que marcar cada uno de los stacks y en la pesta√±a de events podremos ir viendo los recursos que se van creando y su estado. Si todo v abi√©n en unos 10 minutos deber√≠amos tener listo nuestro cluster de Kubernetes. En su defecto esperaremos a que la herramienta nos diga que el cluster ya esta creado y nos lo creeremos ;-)[m
[31m-[m
[32m+[m[32mA partir de aqu√≠ podremos seguir la creaci√≥n de todos estos stacks desde el dashboard de AWS Cloudformation, para los que no est√°is familiarizados con esta herramienta solo hay que marcar cada uno de los stacks y seleccionando la pesta√±a de events podremos ir viendo los recursos que se van creando y su estado. Si todo va bien en unos 10 minutos deber√≠amos tener listo nuestro cluster de Kubernetes. En su defecto esperaremos a que la herramienta nos diga que el cluster ya esta creado y nos lo creeremos ;-)[m
 [m
 ###### kubectl,  la herramienta de interacci√≥n con el cluster[m
 [m
[31m-Para poder interactuar con Kubernetes es necesaria una herramienta de comandos, miento, se puede hacer a trav√©s de una UI que ha ido mejorando notablemente a trav√©s de las versiones pero para sacar realmente la potencia de kubernetes y como todos sabemos, las herramientas en linea de comandos suelen ser bastante mas potentes, escriptables, etc,etc.[m
[32m+[m[32mFinalmente y pare poder verificar que todo ha ido correcto y de que disponemos de nuestro cluster vamos a descargarnos la herramienta de interacci√≥n desde la linea de comandos, podr√≠amos hacer uso del UI Web desde el cual se pueden realizar infinidad de cosas pero como siempre la linea de comandos supera a la UI. Nos la podemos descargar con este sencillo comando:[m
[32m+[m[32m```[m
[32m+[m[32mcurl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl[m
[32m+[m[32m```[m
[32m+[m[32mLa movemos en nuestro /usr/bin o directorio deseado y la marcamos como ejecutable con el chmod +x.[m
[32m+[m[32mUna vez tenemos la herramienta debemos tenemos 2 opciones, cada vez que la ejecutamos especificar el fichero de configuraci√≥n que anteriormente kube-aws nos ha generado(kubeconfig) o hacerlo bien y copiar este fichero y la carpeta de credenciales a una carpeta en nuestro home llamada .kube renombrando el fichero kubeconfig a config, lo podemos hacer f√°cilmente con estos 3 comandos:[m
[32m+[m
[32m+[m[32m```[m
[32m+[m[32mmkdir ~/.kube[m
[32m+[m[32mcp kubeconfig ~/.kube/config[m
[32m+[m[32mcp -r credentials ~/.kube/.[m
[32m+[m[32m```[m
 [m
[32m+[m[32mUna vez hecho este sencillo paso ya podemos verificar si realmente nuestro cluster esta funcionando ejecutando 2 comandos:[m
 [m
[32m+[m[32m```[m
[32m+[m[32mkubectl get nodes[m
[32m+[m[32mNAME                          STATUS    AGE[m
[32m+[m[32mip-10-0-10-119.ec2.internal   Ready     5m[m
[32m+[m[32mip-10-0-10-88.ec2.internal    Ready     6m[m
[32m+[m[32mip-10-0-10-91.ec2.internal    Ready     12m[m
[32m+[m[32mip-10-0-20-100.ec2.internal   Ready     6m[m
[32m+[m[32mip-10-0-20-182.ec2.internal   Ready     6m[m
[32m+[m[32mip-10-0-20-7.ec2.internal     Ready     13m[m
[32m+[m[32m```[m
[32m+[m[32mAqu√≠ lo que hemos hecho es pedirle a Kubernetes que nos muestre todos los nodos que componen el cluster, podemos ver los 6 nodos, 4 workers y 2 masters. Los nodos de etcd no forman parte de Kubernetes , al menos en este tipo de instalaci√≥n.[m
[32m+[m
[32m+[m
[32m+[m[32m```[m
[32m+[m[32mkubectl get pods --namespace=kube-system[m
[32m+[m[32mNAME                                                 READY     STATUS    RESTARTS   AGE[m
[32m+[m[32mheapster-v1.2.0-4088228293-d33tz                     2/2       Running   0          7m[m
[32m+[m[32mkube-apiserver-ip-10-0-10-91.ec2.internal            1/1       Running   0          13m[m
[32m+[m[32mkube-apiserver-ip-10-0-20-7.ec2.internal             1/1       Running   0          14m[m
[32m+[m[32mkube-controller-manager-ip-10-0-10-91.ec2.internal   1/1       Running   0          15m[m
[32m+[m[32mkube-controller-manager-ip-10-0-20-7.ec2.internal    1/1       Running   0          14m[m
[32m+[m[32mkube-dns-782804071-40trf                             4/4       Running   0          16m[m
[32m+[m[32mkube-dns-782804071-l2bk9                             4/4       Running   0          7m[m
[32m+[m[32mkube-dns-autoscaler-2813114833-pqvqf                 1/1       Running   0          16m[m
[32m+[m[32mkube-proxy-ip-10-0-10-119.ec2.internal               1/1       Running   0          8m[m
[32m+[m[32mkube-proxy-ip-10-0-10-88.ec2.internal                1/1       Running   0          8m[m
[32m+[m[32mkube-proxy-ip-10-0-10-91.ec2.internal                1/1       Running   0          14m[m
[32m+[m[32mkube-proxy-ip-10-0-20-100.ec2.internal               1/1       Running   0          8m[m
[32m+[m[32mkube-proxy-ip-10-0-20-182.ec2.internal               1/1       Running   0          8m[m
[32m+[m[32mkube-proxy-ip-10-0-20-7.ec2.internal                 1/1       Running   0          15m[m
[32m+[m[32mkube-scheduler-ip-10-0-10-91.ec2.internal            1/1       Running   0          14m[m
[32m+[m[32mkube-scheduler-ip-10-0-20-7.ec2.internal             1/1       Running   0          14m[m
[32m+[m[32mkubernetes-dashboard-v1.5.1-nd69h                    1/1       Running   0          16m[m
[32m+[m[32m```[m
[32m+[m[32mAqu√≠ listamos todos los Pods (unidades m√≠nimas de servicio) que est√°n corriendo en Kubernetes en el namespace(sistema para aislar zonas en Kubernetes) de kube-system, que es donde corren los servicios core de Kubernetes, si todos est√°n en Running es buena se√±al.[m
\ No newline at end of file[m
